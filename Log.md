<div align="center">

# üìö AIris Development Log


![Phase](https://img.shields.io/badge/Phase-Prototyping-blue?style=for-the-badge)
![Progress](https://img.shields.io/badge/Progress-25%25-green?style=for-the-badge)

---

## Current Sprint: Core Intelligence Development

**Goal:** Evolve the prototype from a simple descriptor to an intelligent action-derivation engine.
**Timeline:** June, July 2025 ~

---

## Development Timeline

<table>
  <tr>
    <td width="15%" align="center"><strong>Date</strong></td>
    <td width="75%"><strong>Entry</strong></td>
  </tr>
  <tr>
    <td align="center">
      <strong>June 1</strong><br/>
      <em>2025</em>
    </td>
    <td>
      <strong>Project Genesis</strong><br/>
      Created README, project structure, finish budgeting<br/>
      <em>Next: Creating visual identity</em><br/>
      <em>- Adib/Rajin</em>
    </td>
  </tr>
  <tr>
    <td align="center">
      <strong>June 11</strong><br/>
      <em>2025</em>
    </td>
    <td>
      <strong>Vision & Mockups</strong><br/>
      Defined the Vision, created a React-based UI mockup, and added initial README.<br/>
      <em>Next: Develop initial working prototype</em><br/>
      <em>- Adib/Rajin</em>
    </td>
  </tr>
  <tr>
    <td align="center">
      <strong>July 15</strong><br/>
      <em>2025</em>
    </td>
    <td>
      <strong>Initial Inference Pipeline</strong><br/>
      Developed the core video-to-description pipeline using Python, Gradio, and the BLIP vision model. Established a fully local, offline-first analysis capability with an interactive web UI for testing.<br/>
      <em>Next: Integrate an LLM to synthesize descriptions into a narrative.</em><br/>
      <em>- Rajin/Adib</em>
    </td>
  </tr>
  <tr>
    <td align="center">
      <strong>July 22</strong><br/>
      <em>2025</em>
    </td>
    <td>
      <strong>Action Derivation Engine & Prompt Engineering</strong><br/>
      Integrated Groq API for high-speed LLM reasoning. Identified and solved challenges with LLM descriptive bias and frame inconsistency through iterative prompt engineering, creating the final "motion analysis expert" prompt to successfully infer actions from static frames.<br/>
      <em>Next: Establish benchmarking metrics (ADA) and research ego-centric datasets.</em><br/>
      <em>- Rajin/Adib, Kabbya</em>
    </td>
  </tr>
  <tr>
    <td align="center">
      <strong>[Date]</strong><br/>
      <em>[Year]</em>
    </td>
    <td>
      <strong>[Title]</strong><br/>
      [What you accomplished]<br/>
      <em>Next: [what's next]</em><br/>
      <em>- Member Name</em>
    </td>
  </tr>
</table>

![Mistakes](https://img.shields.io/badge/Mistakes-‚ùå%20√ó17-red?style=flat-square)
![Coffee](https://img.shields.io/badge/Coffee-‚òï%20√ó37-brown?style=flat-square)

</div>